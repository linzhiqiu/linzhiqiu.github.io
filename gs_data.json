{"container_type": "Author", "filled": ["basics", "publications", "indices", "counts"], "scholar_id": "TFlZ2OcAAAAJ&hl", "source": "AUTHOR_PROFILE_PAGE", "name": "Zhiqiu Lin", "url_picture": "https://scholar.googleusercontent.com/citations?view_op=view_photo&user=TFlZ2OcAAAAJ&citpid=1", "affiliation": "Carnegie Mellon University", "organization": 17554517495610703090, "interests": ["Computer Vision", "Machine Learning", "Human Computer Interaction"], "email_domain": "@andrew.cmu.edu", "homepage": "http://linzhiqiu.github.io/", "citedby": 1499, "publications": {"TFlZ2OcAAAAJ:0EnyYjriUFMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Evaluating text-to-visual generation with image-to-text generation", "pub_year": "2024"}, "filled": false, "author_pub_id": "TFlZ2OcAAAAJ:0EnyYjriUFMC", "num_citations": 254, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4914012604790559131", "cites_id": ["4914012604790559131"]}, "TFlZ2OcAAAAJ:u-x6o8ySG0sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "What. hack: engaging anti-phishing training through a role-playing phishing simulation game", "pub_year": "2019"}, "filled": false, "author_pub_id": "TFlZ2OcAAAAJ:u-x6o8ySG0sC", "num_citations": 191, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4269149149166147661", "cites_id": ["4269149149166147661"]}, "TFlZ2OcAAAAJ:eQOLeE2rZwMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Multimodality helps unimodality: Cross-modal few-shot learning with multimodal models", "pub_year": "2023"}, "filled": false, "author_pub_id": "TFlZ2OcAAAAJ:eQOLeE2rZwMC", "num_citations": 186, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11416070587823639118", "cites_id": ["11416070587823639118"]}, "TFlZ2OcAAAAJ:8k81kl-MbHgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "An introduction to vision-language modeling", "pub_year": "2024"}, "filled": false, "author_pub_id": "TFlZ2OcAAAAJ:8k81kl-MbHgC", "num_citations": 171, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6715432826110828287", "cites_id": ["6715432826110828287"]}, "TFlZ2OcAAAAJ:Y0pCki6q_DkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "The clear benchmark: Continual learning on real-world imagery", "pub_year": "2021"}, "filled": false, "author_pub_id": "TFlZ2OcAAAAJ:Y0pCki6q_DkC", "num_citations": 128, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17993292222696601191", "cites_id": ["17993292222696601191"]}, "TFlZ2OcAAAAJ:3fE2CSJIrl8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "GenAI-Bench: Evaluating and Improving Compositional Text-to-Visual Generation", "pub_year": "2024"}, "filled": false, "author_pub_id": "TFlZ2OcAAAAJ:3fE2CSJIrl8C", "num_citations": 100, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7694773480630475963,4931398775734321318,6310223760778742189", "cites_id": ["7694773480630475963", "4931398775734321318", "6310223760778742189"]}, "TFlZ2OcAAAAJ:d1gkVwhDpl0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Qpytorch: A low-precision arithmetic simulation framework", "pub_year": "2019"}, "filled": false, "author_pub_id": "TFlZ2OcAAAAJ:d1gkVwhDpl0C", "num_citations": 81, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4981780923827266066", "cites_id": ["4981780923827266066"]}, "TFlZ2OcAAAAJ:UebtZRa9Y70C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "The Neglected Tails in Vision-Language Models", "pub_year": "2024"}, "filled": false, "author_pub_id": "TFlZ2OcAAAAJ:UebtZRa9Y70C", "num_citations": 72, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4731107670814865844", "cites_id": ["4731107670814865844"]}, "TFlZ2OcAAAAJ:ufrVoPGSRksC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Revisiting the Role of Language Priors in Vision-Language Models", "pub_year": "2024"}, "filled": false, "author_pub_id": "TFlZ2OcAAAAJ:ufrVoPGSRksC", "num_citations": 63, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11731537112498758874,13754762341203173877", "cites_id": ["11731537112498758874", "13754762341203173877"]}, "TFlZ2OcAAAAJ:KlAtU1dfN6UC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Naturalbench: Evaluating vision-language models on natural adversarial samples", "pub_year": "2024"}, "filled": false, "author_pub_id": "TFlZ2OcAAAAJ:KlAtU1dfN6UC", "num_citations": 54, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5526023683616977271", "cites_id": ["5526023683616977271"]}, "TFlZ2OcAAAAJ:_FxGoFyzp5QC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Language models as black-box optimizers for vision-language models", "pub_year": "2024"}, "filled": false, "author_pub_id": "TFlZ2OcAAAAJ:_FxGoFyzp5QC", "num_citations": 49, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10843004261573175598", "cites_id": ["10843004261573175598"]}, "TFlZ2OcAAAAJ:9yKSN-GCB0IC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Visual chirality", "pub_year": "2020"}, "filled": false, "author_pub_id": "TFlZ2OcAAAAJ:9yKSN-GCB0IC", "num_citations": 41, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7394456161620427993", "cites_id": ["7394456161620427993"]}, "TFlZ2OcAAAAJ:ULOm3_A8WrAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Rim Assouel", "pub_year": "2024"}, "filled": false, "author_pub_id": "TFlZ2OcAAAAJ:ULOm3_A8WrAC", "num_citations": 28, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1525138268118023912", "cites_id": ["1525138268118023912"]}, "TFlZ2OcAAAAJ:roLk4NBRz8UC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Prompting scientific names for zero-shot species recognition", "pub_year": "2023"}, "filled": false, "author_pub_id": "TFlZ2OcAAAAJ:roLk4NBRz8UC", "num_citations": 21, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11346253344015429550", "cites_id": ["11346253344015429550"]}, "TFlZ2OcAAAAJ:WF5omc3nYNoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Continual learning with evolving class ontologies", "pub_year": "2022"}, "filled": false, "author_pub_id": "TFlZ2OcAAAAJ:WF5omc3nYNoC", "num_citations": 17, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12683199090368125947,9019607409563909371", "cites_id": ["12683199090368125947", "9019607409563909371"]}, "TFlZ2OcAAAAJ:kNdYIx-mwKoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Lca-on-the-line: Benchmarking out-of-distribution generalization with class taxonomies", "pub_year": "2024"}, "filled": false, "author_pub_id": "TFlZ2OcAAAAJ:kNdYIx-mwKoC", "num_citations": 13, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14865788217805581136", "cites_id": ["14865788217805581136"]}, "TFlZ2OcAAAAJ:YOwf2qJgpHMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Towards Understanding Camera Motions in Any Video", "pub_year": "2025"}, "filled": false, "author_pub_id": "TFlZ2OcAAAAJ:YOwf2qJgpHMC", "num_citations": 10, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6430670261816087292", "cites_id": ["6430670261816087292"]}, "TFlZ2OcAAAAJ:u5HHmVD_uO8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Streaming self-training via domain-agnostic unlabeled images", "pub_year": "2021"}, "filled": false, "author_pub_id": "TFlZ2OcAAAAJ:u5HHmVD_uO8C", "num_citations": 8, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4021427068231298425", "cites_id": ["4021427068231298425"]}, "TFlZ2OcAAAAJ:2osOgNQ5qMEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Intermediate level adversarial attack for enhanced transferability", "pub_year": "2018"}, "filled": false, "author_pub_id": "TFlZ2OcAAAAJ:2osOgNQ5qMEC", "num_citations": 5, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14268456033179152589", "cites_id": ["14268456033179152589"]}, "TFlZ2OcAAAAJ:_kc_bZDykSQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "InstructPart: Task-Oriented Part Segmentation with Instruction Reasoning", "pub_year": "2025"}, "filled": false, "author_pub_id": "TFlZ2OcAAAAJ:_kc_bZDykSQC", "num_citations": 4, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16362929651821406522,9851146065846709118", "cites_id": ["16362929651821406522", "9851146065846709118"]}, "TFlZ2OcAAAAJ:Zph67rFs4hoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Sparse attention vectors: Generative multimodal model features are discriminative vision-language classifiers", "pub_year": "2024"}, "filled": false, "author_pub_id": "TFlZ2OcAAAAJ:Zph67rFs4hoC", "num_citations": 3, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9422500620344769065", "cites_id": ["9422500620344769065"]}, "TFlZ2OcAAAAJ:4TOpqqG69KYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Activation Reward Models for Few-Shot Model Alignment", "pub_year": "2025"}, "filled": false, "author_pub_id": "TFlZ2OcAAAAJ:4TOpqqG69KYC", "num_citations": 0}, "TFlZ2OcAAAAJ:M3ejUd6NZC8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Enhancing Few-Shot Vision-Language Classification with Large Multimodal Model Features", "pub_year": "2025"}, "filled": false, "author_pub_id": "TFlZ2OcAAAAJ:M3ejUd6NZC8C", "num_citations": 0}, "TFlZ2OcAAAAJ:Tyk-4Ss8FVUC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "2019 Fifth Workshop on Energy Efficient Machine Learning and Cognitive Computing-NeurIPS Edition (EMC2-NIPS)| 978-1-6654-2418-9/19/$31.00© 2019 IEEE| DOI: 10.1109/EMC2 …"}, "filled": false, "author_pub_id": "TFlZ2OcAAAAJ:Tyk-4Ss8FVUC", "num_citations": 0}, "TFlZ2OcAAAAJ:zYLM7Y9cAGgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "EMC2-NIPS 2019"}, "filled": false, "author_pub_id": "TFlZ2OcAAAAJ:zYLM7Y9cAGgC", "num_citations": 0}, "TFlZ2OcAAAAJ:qjMakFHDy7sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Visual Chirality—Supplemental Material: Commutativity and the Chirality of Imaging Processes"}, "filled": false, "author_pub_id": "TFlZ2OcAAAAJ:qjMakFHDy7sC", "num_citations": 0}}, "citedby5y": 1496, "hindex": 15, "hindex5y": 15, "i10index": 17, "i10index5y": 17, "cites_per_year": {"2020": 33, "2021": 45, "2022": 78, "2023": 146, "2024": 427, "2025": 765}, "updated": "2025-10-25 08:02:09.914462"}