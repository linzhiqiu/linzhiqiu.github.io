{"container_type": "Author", "filled": ["basics", "publications", "indices", "counts"], "scholar_id": "TFlZ2OcAAAAJ&hl", "source": "AUTHOR_PROFILE_PAGE", "name": "Zhiqiu Lin", "url_picture": "https://scholar.googleusercontent.com/citations?view_op=view_photo&user=TFlZ2OcAAAAJ&citpid=1", "affiliation": "Carnegie Mellon University", "organization": 17554517495610703090, "interests": ["Computer Vision", "Machine Learning", "Human Computer Interaction"], "email_domain": "@andrew.cmu.edu", "homepage": "http://linzhiqiu.github.io/", "citedby": 1687, "publications": {"TFlZ2OcAAAAJ:0EnyYjriUFMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Evaluating text-to-visual generation with image-to-text generation", "pub_year": "2024"}, "filled": false, "author_pub_id": "TFlZ2OcAAAAJ:0EnyYjriUFMC", "num_citations": 312, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4914012604790559131", "cites_id": ["4914012604790559131"]}, "TFlZ2OcAAAAJ:8k81kl-MbHgC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "An introduction to vision-language modeling", "pub_year": "2024"}, "filled": false, "author_pub_id": "TFlZ2OcAAAAJ:8k81kl-MbHgC", "num_citations": 209, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6715432826110828287", "cites_id": ["6715432826110828287"]}, "TFlZ2OcAAAAJ:eQOLeE2rZwMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Multimodality helps unimodality: Cross-modal few-shot learning with multimodal models", "pub_year": "2023"}, "filled": false, "author_pub_id": "TFlZ2OcAAAAJ:eQOLeE2rZwMC", "num_citations": 195, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11416070587823639118", "cites_id": ["11416070587823639118"]}, "TFlZ2OcAAAAJ:u-x6o8ySG0sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "What. hack: engaging anti-phishing training through a role-playing phishing simulation game", "pub_year": "2019"}, "filled": false, "author_pub_id": "TFlZ2OcAAAAJ:u-x6o8ySG0sC", "num_citations": 194, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4269149149166147661", "cites_id": ["4269149149166147661"]}, "TFlZ2OcAAAAJ:Y0pCki6q_DkC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "The clear benchmark: Continual learning on real-world imagery", "pub_year": "2021"}, "filled": false, "author_pub_id": "TFlZ2OcAAAAJ:Y0pCki6q_DkC", "num_citations": 130, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17993292222696601191", "cites_id": ["17993292222696601191"]}, "TFlZ2OcAAAAJ:3fE2CSJIrl8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "GenAI-Bench: Evaluating and Improving Compositional Text-to-Visual Generation", "pub_year": "2024"}, "filled": false, "author_pub_id": "TFlZ2OcAAAAJ:3fE2CSJIrl8C", "num_citations": 125, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7694773480630475963,4931398775734321318,6310223760778742189", "cites_id": ["7694773480630475963", "4931398775734321318", "6310223760778742189"]}, "TFlZ2OcAAAAJ:UebtZRa9Y70C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "The Neglected Tails in Vision-Language Models", "pub_year": "2024"}, "filled": false, "author_pub_id": "TFlZ2OcAAAAJ:UebtZRa9Y70C", "num_citations": 98, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4731107670814865844,11346253344015429550", "cites_id": ["4731107670814865844", "11346253344015429550"]}, "TFlZ2OcAAAAJ:d1gkVwhDpl0C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Qpytorch: A low-precision arithmetic simulation framework", "pub_year": "2019"}, "filled": false, "author_pub_id": "TFlZ2OcAAAAJ:d1gkVwhDpl0C", "num_citations": 81, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4981780923827266066", "cites_id": ["4981780923827266066"]}, "TFlZ2OcAAAAJ:ufrVoPGSRksC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Revisiting the Role of Language Priors in Vision-Language Models", "pub_year": "2024"}, "filled": false, "author_pub_id": "TFlZ2OcAAAAJ:ufrVoPGSRksC", "num_citations": 71, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11731537112498758874,13754762341203173877", "cites_id": ["11731537112498758874", "13754762341203173877"]}, "TFlZ2OcAAAAJ:KlAtU1dfN6UC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Naturalbench: Evaluating vision-language models on natural adversarial samples", "pub_year": "2024"}, "filled": false, "author_pub_id": "TFlZ2OcAAAAJ:KlAtU1dfN6UC", "num_citations": 70, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5526023683616977271", "cites_id": ["5526023683616977271"]}, "TFlZ2OcAAAAJ:_FxGoFyzp5QC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Language models as black-box optimizers for vision-language models", "pub_year": "2024"}, "filled": false, "author_pub_id": "TFlZ2OcAAAAJ:_FxGoFyzp5QC", "num_citations": 55, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=10843004261573175598", "cites_id": ["10843004261573175598"]}, "TFlZ2OcAAAAJ:9yKSN-GCB0IC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Visual chirality", "pub_year": "2020"}, "filled": false, "author_pub_id": "TFlZ2OcAAAAJ:9yKSN-GCB0IC", "num_citations": 42, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=7394456161620427993", "cites_id": ["7394456161620427993"]}, "TFlZ2OcAAAAJ:ULOm3_A8WrAC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Rim Assouel", "pub_year": "2024"}, "filled": false, "author_pub_id": "TFlZ2OcAAAAJ:ULOm3_A8WrAC", "num_citations": 34, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1525138268118023912", "cites_id": ["1525138268118023912"]}, "TFlZ2OcAAAAJ:WF5omc3nYNoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Continual learning with evolving class ontologies", "pub_year": "2022"}, "filled": false, "author_pub_id": "TFlZ2OcAAAAJ:WF5omc3nYNoC", "num_citations": 17, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=12683199090368125947,9019607409563909371", "cites_id": ["12683199090368125947", "9019607409563909371"]}, "TFlZ2OcAAAAJ:kNdYIx-mwKoC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Lca-on-the-line: Benchmarking out-of-distribution generalization with class taxonomies", "pub_year": "2024"}, "filled": false, "author_pub_id": "TFlZ2OcAAAAJ:kNdYIx-mwKoC", "num_citations": 14, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14865788217805581136", "cites_id": ["14865788217805581136"]}, "TFlZ2OcAAAAJ:YOwf2qJgpHMC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Towards Understanding Camera Motions in Any Video", "pub_year": "2025"}, "filled": false, "author_pub_id": "TFlZ2OcAAAAJ:YOwf2qJgpHMC", "num_citations": 13, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6430670261816087292", "cites_id": ["6430670261816087292"]}, "TFlZ2OcAAAAJ:u5HHmVD_uO8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Streaming self-training via domain-agnostic unlabeled images", "pub_year": "2021"}, "filled": false, "author_pub_id": "TFlZ2OcAAAAJ:u5HHmVD_uO8C", "num_citations": 8, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=4021427068231298425", "cites_id": ["4021427068231298425"]}, "TFlZ2OcAAAAJ:_kc_bZDykSQC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Instructpart: Task-oriented part segmentation with instruction reasoning", "pub_year": "2025"}, "filled": false, "author_pub_id": "TFlZ2OcAAAAJ:_kc_bZDykSQC", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16362929651821406522,9851146065846709118", "cites_id": ["16362929651821406522", "9851146065846709118"]}, "TFlZ2OcAAAAJ:M3ejUd6NZC8C": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Enhancing Few-Shot Vision-Language Classification with Large Multimodal Model Features", "pub_year": "2025"}, "filled": false, "author_pub_id": "TFlZ2OcAAAAJ:M3ejUd6NZC8C", "num_citations": 6, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=9422500620344769065,17893922526602380245", "cites_id": ["9422500620344769065", "17893922526602380245"]}, "TFlZ2OcAAAAJ:2osOgNQ5qMEC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Intermediate level adversarial attack for enhanced transferability", "pub_year": "2018"}, "filled": false, "author_pub_id": "TFlZ2OcAAAAJ:2osOgNQ5qMEC", "num_citations": 5, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=14268456033179152589", "cites_id": ["14268456033179152589"]}, "TFlZ2OcAAAAJ:4TOpqqG69KYC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Activation Reward Models for Few-Shot Model Alignment", "pub_year": "2025"}, "filled": false, "author_pub_id": "TFlZ2OcAAAAJ:4TOpqqG69KYC", "num_citations": 2, "citedby_url": "https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3021746217143659952", "cites_id": ["3021746217143659952"]}, "TFlZ2OcAAAAJ:qjMakFHDy7sC": {"container_type": "Publication", "source": "AUTHOR_PUBLICATION_ENTRY", "bib": {"title": "Visual Chiralityâ€”Supplemental Material: Commutativity and the Chirality of Imaging Processes"}, "filled": false, "author_pub_id": "TFlZ2OcAAAAJ:qjMakFHDy7sC", "num_citations": 0}}, "citedby5y": 1650, "hindex": 14, "hindex5y": 14, "i10index": 16, "i10index5y": 16, "cites_per_year": {"2020": 33, "2021": 45, "2022": 78, "2023": 144, "2024": 417, "2025": 962, "2026": 3}, "updated": "2026-01-05 08:02:29.517523"}